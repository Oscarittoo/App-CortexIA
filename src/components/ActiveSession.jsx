import { useState, useEffect, useRef } from 'react';
import { Mic, MicOff, Pause, Play, Square, AlertCircle, CheckCircle, AlertTriangle } from 'lucide-react';

export default function ActiveSession({ config, onEnd }) {
  const [transcript, setTranscript] = useState([]);
  const [duration, setDuration] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [micStatus, setMicStatus] = useState('Initialisation...');
  const [audioDetected, setAudioDetected] = useState(false);
  const [speechDetected, setSpeechDetected] = useState(false);
  const [detectedActions, setDetectedActions] = useState([]);
  const [detectedDecisions, setDetectedDecisions] = useState([]);
  const recognitionRef = useRef(null);
  const transcriptEndRef = useRef(null);
  const restartCountRef = useRef(0);
  const isPausedRef = useRef(false);
  const durationRef = useRef(0);

  useEffect(() => {
    startRecording();
    const timer = setInterval(() => {
      if (!isPausedRef.current) {
        durationRef.current += 1;
        setDuration(durationRef.current);
      }
    }, 1000);

    return () => {
      clearInterval(timer);
      stopRecording();
    };
  }, []);

  // Synchroniser le ref avec le state
  useEffect(() => {
    isPausedRef.current = isPaused;
  }, [isPaused]);

  useEffect(() => {
    // Auto-scroll vers le bas
    transcriptEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [transcript]);

  const startRecording = async () => {
    try {
      console.log('=== D√âBUT INITIALISATION TRANSCRIPTION ===');
      console.log('Configuration:', config);
      setMicStatus('üîÑ Initialisation Web Speech API...');

      // V√©rifier support Web Speech API
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        throw new Error('Web Speech API non support√©e par ce navigateur');
      }

      console.log('‚úÖ Web Speech API support√©e');

      // Cr√©er l'instance de reconnaissance
      const recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = config.language === 'fr' ? 'fr-FR' : 'en-US';
      recognition.maxAlternatives = 1;

      console.log('Configuration reconnaissance:', {
        continuous: recognition.continuous,
        interimResults: recognition.interimResults,
        lang: recognition.lang
      });

      // === EVENT HANDLERS AVEC LOGS D√âTAILL√âS ===

      recognition.onstart = () => {
        console.log('‚úÖ [onstart] Recognition started successfully');
        setMicStatus('‚úÖ √âcoute active - Parlez maintenant');
        setIsRecording(true);
      };

      recognition.onaudiostart = () => {
        console.log('üé§ [onaudiostart] Audio capture active');
        setAudioDetected(true);
      };

      recognition.onsoundstart = () => {
        console.log('üîä [onsoundstart] Sound detected');
      };

      recognition.onspeechstart = () => {
        console.log('üó£Ô∏è [onspeechstart] Speech detected');
        setSpeechDetected(true);
        setMicStatus('üó£Ô∏è Parole d√©tect√©e...');
      };

      recognition.onresult = (event) => {
        console.log('üìù [onresult] Result received, results count:', event.results.length);
        
        const last = event.results.length - 1;
        const result = event.results[last];
        let text = result[0].transcript;
        const confidence = result[0].confidence;
        const isFinal = result.isFinal;

        // Log du texte brut pour debug
        console.log('Texte brut:', JSON.stringify(text));
        // Nettoyage : supprime les '0' parasites en fin de texte (.0, 0 seul, ou espace+0)
        text = text.trim().replace(/[\s\.]*0+$/g, '');

        console.log('Transcription:', {
          text,
          confidence: confidence ? (confidence * 100).toFixed(1) + '%' : 'N/A',
          isFinal,
          resultIndex: last
        });

        if (isFinal) {
          console.log('‚úÖ R√©sultat final ajout√© √† la transcription');
          setMicStatus('‚úÖ Transcription active');
          
          const newEntry = {
            id: Date.now(),
            timestamp: Date.now(),
            text: text.trim().replace(/[\s\.]*0+$/g, ''),
            speaker: 'Participant',
            confidence: confidence,
            isFinal: true
          };
          
          setTranscript(prev => [...prev, newEntry]);
          
          // Analyse IA en temps r√©el
          analyzeTextForActionsAndDecisions(text);
        } else {
          const preview = text.length > 40 ? text.substring(0, 40) + '...' : text;
          setMicStatus(`üé§ ${preview}`);
        }
      };

      recognition.onspeechend = () => {
        console.log('‚è∏Ô∏è [onspeechend] Speech ended');
        setSpeechDetected(false);
      };

      recognition.onsoundend = () => {
        console.log('üîá [onsoundend] Sound ended');
      };

      recognition.onaudioend = () => {
        console.log('‚èπÔ∏è [onaudioend] Audio capture ended');
        setAudioDetected(false);
      };

      recognition.onerror = (event) => {
        console.error('‚ùå [onerror] Error occurred:', event.error);
        console.error('Error details:', {
          error: event.error,
          message: event.message || 'No message'
        });

        let errorMessage = '';
        switch (event.error) {
          case 'no-speech':
            errorMessage = '‚ö†Ô∏è Aucune parole d√©tect√©e - parlez plus fort';
            console.warn('Conseil: Assurez-vous que le microphone fonctionne et que vous parlez clairement');
            break;
          case 'audio-capture':
            errorMessage = '‚ùå Impossible de capturer l\'audio';
            console.error('Le microphone est peut-√™tre utilis√© par une autre application');
            break;
          case 'not-allowed':
            errorMessage = '‚ùå Permission microphone refus√©e';
            console.error('Autorisez l\'acc√®s au microphone dans les param√®tres du navigateur');
            alert('‚ùå Acc√®s au microphone refus√©. Veuillez autoriser l\'acc√®s dans les param√®tres de votre navigateur.');
            break;
          case 'network':
            errorMessage = '‚ùå Erreur r√©seau';
            console.error('V√©rifiez votre connexion internet');
            break;
          case 'aborted':
            errorMessage = '‚ö†Ô∏è Reconnaissance interrompue';
            break;
          default:
            errorMessage = `‚ùå Erreur: ${event.error}`;
        }
        
        setMicStatus(errorMessage);
      };

      recognition.onend = () => {
        console.log('üîÑ [onend] Recognition ended');
        
        if (isRecording && !isPaused && restartCountRef.current < 50) {
          console.log(`üîÑ Auto-restart (tentative ${restartCountRef.current + 1}/50)`);
          restartCountRef.current += 1;
          
          setTimeout(() => {
            try {
              recognition.start();
              console.log('‚úÖ Recognition restarted');
            } catch (error) {
              console.error('‚ùå Restart failed:', error);
              setMicStatus('‚ùå Erreur red√©marrage reconnaissance');
            }
          }, 100);
        } else if (restartCountRef.current >= 50) {
          console.warn('‚ö†Ô∏è Limite de red√©marrage atteinte (50)');
          setMicStatus('‚ö†Ô∏è Limite de red√©marrage atteinte');
        }
      };

      // D√©marrer la reconnaissance
      console.log('üöÄ Tentative de d√©marrage...');
      recognitionRef.current = recognition;
      recognition.start();
      
      console.log('=== INITIALISATION TERMIN√âE ===');
      setMicStatus('üîÑ D√©marrage en cours...');

    } catch (error) {
      console.error('‚ùå ERREUR FATALE:', error);
      console.error('Stack trace:', error.stack);
      setMicStatus('‚ùå Erreur: ' + error.message);
      alert('‚ùå Erreur d\'initialisation: ' + error.message);
    }
  };

  const stopRecording = () => {
    console.log('üõë Arr√™t de la reconnaissance');
    if (recognitionRef.current) {
      recognitionRef.current.stop();
      recognitionRef.current = null;
    }
    setIsRecording(false);
    setAudioDetected(false);
    setSpeechDetected(false);
  };

  const handlePauseResume = () => {
    if (isPaused) {
      console.log('‚ñ∂Ô∏è Reprise de la session');
      if (recognitionRef.current) {
        recognitionRef.current.start();
      }
      setTranscript(prev => [...prev, {
        id: Date.now(),
        timestamp: Date.now(),
        text: '‚ñ∂ Session reprise',
        speaker: 'Syst√®me',
        isSystem: true
      }]);
    } else {
      console.log('‚è∏Ô∏è Pause de la session');
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      setTranscript(prev => [...prev, {
        id: Date.now(),
        timestamp: Date.now(),
        text: '‚è∏ Session en pause',
        speaker: 'Syst√®me',
        isSystem: true
      }]);
    }
    setIsPaused(!isPaused);
  };

  // Analyse IA en temps r√©el des actions et d√©cisions
  const analyzeTextForActionsAndDecisions = (text) => {
    const lowerText = text.toLowerCase();
    
    // Mots-cl√©s pour actions
    const actionKeywords = [
      'doit', 'dois', 'devons', 'devez', 'va', 'vais', 'allons', 'allez',
      'devra', 'faut', 'il faut', 'faudra', 'besoin', 'action', 'faire',
      'r√©aliser', 't√¢che', 'planifier', 'organiser', 'pr√©parer', 'pr√©voir',
      'cr√©er', 'mettre en place', 'lancer', 'd√©velopper', 'impl√©menter',
      '√† suivre', 'next step', 'prochaine √©tape', 'todo'
    ];
    
    // Mots-cl√©s pour d√©cisions
    const decisionKeywords = [
      'd√©cidons', 'd√©cid√©', 'd√©cision', 'on part sur', 'on choisit',
      'on valide', 'valid√©', 'approuv√©', 'refus√©', 'rejet√©', 'accept√©',
      'accord', 'd\'accord', 'ok pour', 'go pour', 'on fait', 'on ne fait pas',
      'd√©cide', 'resolved', 'r√©solu', 'statu√©', 'tranch√©'
    ];
    
    // D√©tection d'action
    const hasAction = actionKeywords.some(keyword => lowerText.includes(keyword));
    if (hasAction) {
      const newAction = {
        id: Date.now() + Math.random(),
        text: text.trim(),
        timestamp: new Date().toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' }),
        priority: determinePriority(text)
      };
      
      setDetectedActions(prev => {
        // √âviter les doublons
        const isDuplicate = prev.some(action => 
          action.text.toLowerCase() === newAction.text.toLowerCase()
        );
        if (!isDuplicate) {
          return [...prev, newAction];
        }
        return prev;
      });
    }
    
    // D√©tection de d√©cision
    const hasDecision = decisionKeywords.some(keyword => lowerText.includes(keyword));
    if (hasDecision) {
      const newDecision = {
        id: Date.now() + Math.random(),
        text: text.trim(),
        timestamp: new Date().toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' }),
        impact: determineImpact(text)
      };
      
      setDetectedDecisions(prev => {
        // √âviter les doublons
        const isDuplicate = prev.some(decision => 
          decision.text.toLowerCase() === newDecision.text.toLowerCase()
        );
        if (!isDuplicate) {
          return [...prev, newDecision];
        }
        return prev;
      });
    }
  };

  const determinePriority = (text) => {
    const urgent = ['urgent', 'imm√©diat', 'asap', 'prioritaire', 'critique'];
    const high = ['important', 'doit', 'faut', 'rapidement', 'vite'];
    
    const lowerText = text.toLowerCase();
    if (urgent.some(word => lowerText.includes(word))) return 'Haute';
    if (high.some(word => lowerText.includes(word))) return 'Moyenne';
    return 'Basse';
  };

  const determineImpact = (text) => {
    const high = ['strat√©gique', 'majeur', 'important', 'critique', 'essentiel'];
    const medium = ['significatif', 'notable', 'cons√©quent'];
    
    const lowerText = text.toLowerCase();
    if (high.some(word => lowerText.includes(word))) return 'Fort';
    if (medium.some(word => lowerText.includes(word))) return 'Moyen';
    return 'Faible';
  };

  const handleStop = () => {
    if (confirm('üõë Voulez-vous vraiment terminer cette session ?')) {
      stopRecording();
      // Ajouter les actions et d√©cisions d√©tect√©es √† la session
      const enhancedData = {
        ...transcript,
        detectedActions,
        detectedDecisions
      };
      onEnd(transcript, duration, { detectedActions, detectedDecisions });
    }
  };

  const handleMarkMoment = () => {
    const note = prompt('üìå Note pour ce moment important :');
    if (note) {
      setTranscript(prev => [...prev, {
        id: Date.now(),
        timestamp: Date.now(),
        text: `üìå ${note}`,
        speaker: 'Syst√®me',
        marked: true
      }]);
    }
  };

  const formatDuration = (seconds) => {
    const hrs = Math.floor(seconds / 3600);
    const mins = Math.floor((seconds % 3600) / 60);
    const secs = seconds % 60;
    if (hrs > 0) {
      return `${hrs}:${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    }
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="screen active-session">
      <div className="session-layout">
        {/* Panneau principal - Transcription */}
        <div className="session-main">
          <div className="session-header">
            <div className="session-info">
              <h2>{config.title}</h2>
              <div className="recording-indicator">
                {!isPaused && <span className="red-dot"></span>}
                {isPaused ? '‚è∏Ô∏è En pause' : 'üî¥ Enregistrement en cours'} ‚Ä¢ {formatDuration(duration)}
              </div>
              
              <div className="mic-status" style={{ fontSize: '14px', marginTop: '8px', opacity: 0.8 }}>
                {micStatus}
              </div>

              {/* Indicateurs de d√©tection */}
              <div style={{ display: 'flex', gap: '12px', marginTop: '8px', fontSize: '12px' }}>
            <div style={{ 
              display: 'flex', 
              alignItems: 'center', 
              gap: '4px',
              color: audioDetected ? '#10b981' : '#94a3b8',
              fontWeight: audioDetected ? '600' : '400'
            }}>
              <Mic size={14} />
              Audio: {audioDetected ? '‚úì Actif' : '‚óã Inactif'}
            </div>
            <div style={{ 
              display: 'flex', 
              alignItems: 'center', 
              gap: '4px',
              color: speechDetected ? '#10b981' : '#94a3b8',
              fontWeight: speechDetected ? '600' : '400'
            }}>
              <AlertCircle size={14} />
              Parole: {speechDetected ? '‚úì D√©tect√©e' : '‚óã Aucune'}
            </div>
          </div>

          <div style={{ fontSize: '11px', marginTop: '6px', color: '#64748b', fontStyle: 'italic' }}>
            üí° Ouvrez la console (F12) pour voir les logs d√©taill√©s
          </div>
        </div>
      </div>

      {/* D√©tection d'environnement Electron */}
      {(() => {
        const isElectron = typeof window !== 'undefined' && window.process && window.process.type === 'renderer';
        if (!isElectron) return null;
        return (
          <div style={{
            background: '#fff3cd',
            color: '#856404',
            border: '1px solid #ffeeba',
            borderRadius: '8px',
            padding: '16px',
            marginBottom: '18px',
            fontSize: '15px',
            maxWidth: '600px',
            margin: '0 auto 18px auto',
            textAlign: 'center',
          }}>
            <b>‚ö†Ô∏è La transcription vocale ne fonctionne pas dans l'application install√©e.</b><br />
            <span style={{ fontSize: '14px' }}>
              Veuillez utiliser la version navigateur (Chrome/Edge/Brave) pour profiter de la transcription en temps r√©el.<br />
              <span style={{ color: '#b91c1c', fontWeight: 500 }}>Limitation technique Electron/Web Speech API</span>
            </span>
          </div>
        );
      })()}
      <div className="transcript-container">
        <div className="transcript-stats">
          {transcript.filter(t => t.isFinal).length} segments ‚Ä¢ 
          üìå {transcript.filter(t => t.marked).length} moments marqu√©s
        </div>
        
        {transcript.length === 0 && (
          <div className="transcript-empty">
            <div style={{ marginBottom: '16px' }}>
              <Mic size={48} style={{ color: audioDetected ? '#10b981' : '#94a3b8' }} />
            </div>
            <p>üé§ En attente de parole...</p>
            <small>Commencez √† parler pour voir la transcription appara√Ætre</small>
            <br />
            <small style={{ marginTop: '12px', display: 'block', color: '#666' }}>
              Statut: {micStatus}
            </small>
            {!audioDetected && isRecording && (
              <div style={{ 
                marginTop: '16px', 
                padding: '12px', 
                background: '#fff3cd', 
                borderRadius: '8px',
                fontSize: '13px',
                color: '#856404'
              }}>
                <AlertCircle size={16} style={{ marginBottom: '4px' }} />
                <div>‚ö†Ô∏è Aucun audio d√©tect√©</div>
                <div style={{ marginTop: '4px', fontSize: '12px' }}>
                  V√©rifiez que votre microphone fonctionne et que les permissions sont accord√©es
                </div>
              </div>
            )}
          </div>
        )}

        {transcript.map((item) => (
          <div 
            key={item.id} 
            className={`transcript-line ${item.marked ? 'marked' : ''} ${item.isSystem ? 'system' : ''}`}
          >
            <span className="timestamp">
              {new Date(item.timestamp).toLocaleTimeString('fr-FR', { 
                hour: '2-digit', 
                minute: '2-digit',
                second: '2-digit'
              })}
            </span>
            <span className="speaker">{item.speaker}:</span>
            <span className="text">{typeof item.text === 'string' ? item.text.trim().replace(/[\s\.]*0+$/g, '') : item.text}</span>
            {item.confidence && (
              <span style={{ 
                fontSize: '11px', 
                color: '#94a3b8', 
                marginLeft: '8px' 
              }}>
                ({(item.confidence * 100).toFixed(0)}%)
              </span>
            )}
          </div>
        ))}
        <div ref={transcriptEndRef} />
      </div>

      <div className="session-controls">
        <button 
          onClick={handlePauseResume} 
          className={`btn-secondary ${isPaused ? 'btn-resume' : ''}`}
          style={{ display: 'flex', alignItems: 'center', gap: '8px', justifyContent: 'center' }}
        >
          {isPaused ? <><Play size={18} /> Reprendre</> : <><Pause size={18} /> Pause</>}
        </button>
        
        <button 
          onClick={handleMarkMoment} 
          className="btn-secondary"
          style={{ display: 'flex', alignItems: 'center', gap: '8px', justifyContent: 'center' }}
        >
          üìå Marquer ce moment
        </button>
        
        <button 
          onClick={handleStop} 
          className="btn-danger"
          style={{ display: 'flex', alignItems: 'center', gap: '8px', justifyContent: 'center' }}
        >
          <Square size={18} /> Terminer la session
        </button>
      </div>
        </div>

        {/* Panneau lat√©ral - Analyse IA en temps r√©el */}
        <div className="session-sidebar">
          <div className="ai-panel">
            <h3 className="ai-panel-title">ü§ñ Analyse IA en temps r√©el</h3>
            
            {/* Actions d√©tect√©es */}
            <div className="ai-section">
              <div className="ai-section-header">
                <CheckCircle size={18} />
                <h4>Actions √† suivre</h4>
                <span className="ai-badge">{detectedActions.length}</span>
              </div>
              
              <div className="ai-items">
                {detectedActions.length === 0 ? (
                  <div className="ai-empty">
                    Aucune action d√©tect√©e pour le moment
                  </div>
                ) : (
                  detectedActions.map(action => (
                    <div key={action.id} className="ai-item action-item">
                      <div className="ai-item-meta">
                        <span className="ai-time">{action.timestamp}</span>
                        <span className={`priority-badge priority-${action.priority.toLowerCase()}`}>
                          {action.priority}
                        </span>
                      </div>
                      <div className="ai-item-text">{action.text}</div>
                    </div>
                  ))
                )}
              </div>
            </div>

            {/* D√©cisions d√©tect√©es */}
            <div className="ai-section">
              <div className="ai-section-header">
                <AlertTriangle size={18} />
                <h4>D√©cisions prises</h4>
                <span className="ai-badge">{detectedDecisions.length}</span>
              </div>
              
              <div className="ai-items">
                {detectedDecisions.length === 0 ? (
                  <div className="ai-empty">
                    Aucune d√©cision d√©tect√©e pour le moment
                  </div>
                ) : (
                  detectedDecisions.map(decision => (
                    <div key={decision.id} className="ai-item decision-item">
                      <div className="ai-item-meta">
                        <span className="ai-time">{decision.timestamp}</span>
                        <span className={`impact-badge impact-${decision.impact.toLowerCase()}`}>
                          Impact {decision.impact}
                        </span>
                      </div>
                      <div className="ai-item-text">{decision.text}</div>
                    </div>
                  ))
                )}
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
